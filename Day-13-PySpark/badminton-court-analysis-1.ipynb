{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbced51-42d0-4074-973e-9ac17a1aad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0e5cf5-2d1d-4597-9711-16260b82b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Badminton Court Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fbd819-63f0-4965-8fb1-2b56c9d08538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://e82399e7e1cc:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Badminton Court Analysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa6a408a910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744a665a-d753-4dda-858e-1d11d88ce314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema corresponding to the data\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"kit_id\", IntegerType(), True),\n",
    "    StructField(\"login_date\", StringType(), True),\n",
    "    StructField(\"session_count\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21725111-c116-48c2-9e01-7144e87e29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, 2, \"2016-03-01\", 5),\n",
    "    (1, 2, \"2016-03-02\", 6),\n",
    "    (2, 3, \"2017-06-25\", 1),\n",
    "    (3, 1, \"2016-03-02\", 0),\n",
    "    (3, 4, \"2018-07-03\", 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123069d1-b4f7-4b25-9e7c-2a19aa11983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "input_df = spark.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d5ff16-ccb1-4692-88c0-6aab31b3bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: Determine the eaarliest login date of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f7cda4-36c9-4857-9989-e45e74a45bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soltion in SQL\n",
    "\n",
    "# -- Using Window function\n",
    "# -- Solution: \n",
    "# WITH ranked_cte AS\n",
    "# \t(\n",
    "# \t\tSELECT\n",
    "# \t\t\t*,\n",
    "# \t\t\tROW_NUMBER() OVER (PARTITION BY  user_id ORDER BY login_date) AS rn \n",
    "# \t\tFROM\n",
    "# \t\t\tcourt\n",
    "# \t)\n",
    "# SELECT\n",
    "# \tuser_id,\n",
    "# \tlogin_date AS first_login\n",
    "# FROM\n",
    "# \tranked_cte\n",
    "# WHERE\n",
    "# \trn = 1;\n",
    "\n",
    "# -- Note\n",
    "# -- With aggregate or group by, we los information as we can only select aggregated column on dimension columns \n",
    "# -- by which aggregation is performed\n",
    "# -- Whereas with window function we do not loose info as aggregation is performed on a window separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f812636-3fc3-48da-8209-45497d483d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+-------------+\n",
      "|user_id|kit_id|login_date|session_count|\n",
      "+-------+------+----------+-------------+\n",
      "|      1|     2|2016-03-01|            5|\n",
      "|      1|     2|2016-03-02|            6|\n",
      "|      2|     3|2017-06-25|            1|\n",
      "|      3|     1|2016-03-02|            0|\n",
      "|      3|     4|2018-07-03|            5|\n",
      "+-------+------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c438e-fda5-4c3f-856d-95b243674deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62c0566-61b6-4ae6-89ec-139bfae92d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach - 1: Using Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0fd118-1e71-4dff-88af-6deea137dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = input_df.groupBy(\"user_id\").agg(\n",
    "    f.min(\"login_date\").alias(\"first_login\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d8258b-6acb-465b-8c2b-6749c3acd024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|user_id|first_login|\n",
      "+-------+-----------+\n",
      "|      1| 2016-03-01|\n",
      "|      2| 2017-06-25|\n",
      "|      3| 2016-03-02|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a64bbb64-ed63-4290-927b-465780b9a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach - 2: Window function\n",
    "windowSpec = Window.partitionBy(\"user_id\").orderBy(\"login_date\")\n",
    "\n",
    "ranked_df = input_df.withColumn(\n",
    "    \"rnk\", f.rank().over(windowSpec)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26828777-1aa9-449a-9c98-af43b8e17865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+-------------+---+\n",
      "|user_id|kit_id|login_date|session_count|rnk|\n",
      "+-------+------+----------+-------------+---+\n",
      "|      1|     2|2016-03-01|            5|  1|\n",
      "|      1|     2|2016-03-02|            6|  2|\n",
      "|      2|     3|2017-06-25|            1|  1|\n",
      "|      3|     1|2016-03-02|            0|  1|\n",
      "|      3|     4|2018-07-03|            5|  2|\n",
      "+-------+------+----------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranked_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c35a37-66aa-4c5a-8cad-5e0aa5f554e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = ranked_df.filter(f.col(\"rnk\") == 1)\n",
    "# or\n",
    "# result_df = ranked_df.filter(ranked_df[\"rnk\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e14b0ae7-2bce-4e04-b180-40d8257be861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+-------------+---+\n",
      "|user_id|kit_id|login_date|session_count|rnk|\n",
      "+-------+------+----------+-------------+---+\n",
      "|      1|     2|2016-03-01|            5|  1|\n",
      "|      2|     3|2017-06-25|            1|  1|\n",
      "|      3|     1|2016-03-02|            0|  1|\n",
      "+-------+------+----------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3091d4d-bf42-4ea6-9345-0d385e1583bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one step closer\n",
    "result = ranked_df.select(\n",
    "    f.col(\"user_id\"), \n",
    "    f.col(\"login_date\").alias(\"first_login\")\n",
    ").filter(f.col(\"rnk\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca73f8b7-333e-46af-aa40-9f090d2642c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|user_id|first_login|\n",
      "+-------+-----------+\n",
      "|      1| 2016-03-01|\n",
      "|      2| 2017-06-25|\n",
      "|      3| 2016-03-02|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc2c7ac-9bd9-4eda-938d-f298e9e2c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some questions\n",
    "# 1. Difference between sparkcontext and sparksession\n",
    "# 2. what is transformation and what is action\n",
    "# 3. Why transformation is lazy? And why laziness needed, it's benefits?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
